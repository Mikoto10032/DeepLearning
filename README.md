# DeepLearning

## 入门资料   
  
* [1. 《深度学习》 Yoshua Bengio.Ian GoodFellow](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.Yoshua%20Bengio%2BIan%20GoodFellow.pdf)      
* [2. 《机器学习》 周志华](https://github.com/Mikoto10032/DeepLearning/blob/master/books/机器学习周志华.pdf)        
* [3. 《神经网络与深度学习》 Michael Nielsen](https://github.com/Mikoto10032/DeepLearning/blob/master/books/神经网络和深度学习neural%20networks%20and%20deep-learning-中文_ALL.pdf)    
* [4. 《斯坦福大学深度学习基础教程》 Andrew Ng（吴恩达）](https://github.com/Mikoto10032/DeepLearning/blob/master/books/斯坦福大学-深度学习基础教程.pdf)      
* [5. 《模式识别与机器学习》 Christopher Bishop](https://github.com/Mikoto10032/DeepLearning/blob/master/books/模式识别与机器学习PRML_Chinese_vision.pdf)
* [6. 《Tensorflow实战Google深度学习框架》 郑泽宇 顾思宇](https://github.com/Mikoto10032/DeepLearning/blob/master/books/Tensorflow%20实战Google深度学习框架.pdf)
* [7. 《机器学习实战》 PelerHarrington](https://github.com/Mikoto10032/DeepLearning/blob/master/books/机器学习实战%20中文双页版.pdf)
* [8. 机器学习 吴恩达 cs229个人笔记](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-CS229%5D%5B2011%5D%5BAndrew%20NG%5D/%5B2011%5D%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E4%B8%AA%E4%BA%BA%E7%AC%94.pdf)
   * [官网（笔记）](http://cs229.stanford.edu/)  
   * [视频（中文字幕）](http://open.163.com/special/opencourse/machinelearning.html)
* [9. 机器学习 吴恩达 Coursera个人笔记](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%5BML-Coursera%5D%5B2014%5D%5BAndrew%20Ng%5D/%5B2014%5D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88v5.1.pdf)  
    * [视频（含官方笔记）](https://www.coursera.org/learn/machine-learning)      
* [10. 深度学习 吴恩达 个人笔记](http://www.ai-start.com/dl2017/)  
    * [视频](http://mooc.study.163.com/smartSpec/detail/1001319001.htm)
* [11. 深度学习 李飞飞 已授权个人翻译笔记](https://zhuanlan.zhihu.com/p/21930884)        
    * [视频](http://study.163.com/course/courseMain.htm?courseId=1003223001)
* [12. 台湾大学（NTU）李宏毅教授课程](http://speech.ee.ntu.edu.tw/~tlkagk/index.html)	
* [13. 《自然语言处理》Jacob Eisenstein](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.Jacob%20Eisenstein.pdf)		
* [14. 《强化学习》](https://github.com/Mikoto10032/DeepLearning/blob/master/books/Reinforcement%20Learning.Sutton.pdf)	
* [15. hangdong的深度学习博客,论文推荐](https://handong1587.github.io/categories.html#deep_learning-ref)
* [16. CS20:Tensorflow for DeepLearning Research](http://web.stanford.edu/class/cs20si/syllabus.html)
* [17. CS321-Hinton](http://www.cs.toronto.edu/~tijmen/csc321/)
* [18. 深度学习思维导图](https://github.com/dformoso/deeplearning-mindmap)		
* [19. CS230: Deep Learning](https://web.stanford.edu/class/cs230/)		
* [20. CS294-112](http://rail.eecs.berkeley.edu/deeprlcourse/resources/)

## 神经网络模型概览		

* [1. 一文看懂25个神经网络模型](https://blog.csdn.net/qq_35082030/article/details/73368962)
* [2. DNN概述论文：详解前馈、卷积和循环神经网络技术](https://zhuanlan.zhihu.com/p/29141828)
* [3. colah's blog](http://colah.github.io/)
* [4. Model Zoom](https://modelzoo.co/)
* [5. DNN概述](https://zhuanlan.zhihu.com/p/29141828)

### CNN     

#### 发展史    

* [1. 94页论文综述卷积神经网络：从基础技术到研究前景](https://zhuanlan.zhihu.com/p/35388569)
* [2. 从LeNet-5到DenseNet](https://zhuanlan.zhihu.com/p/31006686)       
* [3. CNN图像分割简史：从R-CNN到Mask R-CNN（译）](https://zhuanlan.zhihu.com/p/26652657)      
* [4. 深度学习之目标检测的前世今生（Mask R-CNN）](https://zhuanlan.zhihu.com/p/32830206)      
* [5. 纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception](https://zhuanlan.zhihu.com/p/32746221)   
* [6. 深度学习目标检测模型全面综述：Faster R-CNN、R-FCN和SSD](https://zhuanlan.zhihu.com/p/29434605)      
* [7. 图像语义分割(Semantic segmentation) Survey](https://zhuanlan.zhihu.com/p/36801104)
* [7. 从RCNN到SSD，这应该是最全的一份目标检测算法盘点](https://zhuanlan.zhihu.com/p/36184131)    
* [8. 图像语义分割(Semantic segmentation) Survey](https://zhuanlan.zhihu.com/p/36801104)      
* [9. 语义分割 发展综述](https://zhuanlan.zhihu.com/p/37618829)       
* [深度学习分类网络](https://blog.csdn.net/PeaceInMind/article/details/78079263)
* [卷积神经网络结构演变（form Hubel and Wiesel to SENet）](https://zhuanlan.zhihu.com/p/34621135)
* [从VGG到NASNet，一文概览图像分类网络](https://zhuanlan.zhihu.com/p/35221368)
* [From RCNN to YOLO]()：[上](https://zhuanlan.zhihu.com/p/35724768)，[下](https://zhuanlan.zhihu.com/p/35731743)
* [后 R-CNN时代， Faster R-CNN、SSD、YOLO 各类变体统治下的目标检测综述：Faster R-CNN系列胜了吗？](https://zhuanlan.zhihu.com/p/38709522)
* [目标检测-20种模型的原味代码汇总](https://zhuanlan.zhihu.com/p/37056927)     
* [目标检测算法综述三部曲](https://zhuanlan.zhihu.com/p/40047760)
	* [基于深度学习的目标检测算法综述（一）
](https://zhuanlan.zhihu.com/p/40047760)
	* [基于深度学习的目标检测算法综述（二）](https://zhuanlan.zhihu.com/p/40020809)
	* [基于深度学习的目标检测算法综述（三）](https://zhuanlan.zhihu.com/p/40102001)
* [如何走近深度学习人脸识别？你需要这篇超长综述 | 附开源代码](https://zhuanlan.zhihu.com/p/35295839)    

#### 教程     

* [卷积神经网络工作原理](https://www.zhihu.com/question/39022858)
* [变形卷积核、可分离卷积](https://zhuanlan.zhihu.com/p/28749411)
* [各种卷积](https://www.cnblogs.com/cvtoEyes/p/8848815.html)
* [反卷积](https://buptldy.github.io/2016/10/29/2016-10-29-deconv/) 
* [Convolution Network及其变种（反卷积、扩展卷积、因果卷积、图卷积）](https://www.cnblogs.com/yangperasd/p/7071657.html)
* [Dilated/Atrous conv 空洞卷积/多孔卷积](https://blog.csdn.net/silence2015/article/details/79748729)
* [CNN模型之ShuffleNet](https://zhuanlan.zhihu.com/p/32304419)  
* [一文简述ResNet及其多种变体](https://zhuanlan.zhihu.com/p/35985680)
* [ResNet解析](https://blog.csdn.net/lanran2/article/details/79057994)
* [将CNN引入目标检测的开山之作：R-CNN](https://zhuanlan.zhihu.com/p/23006190)     
* [深度学习（十八）基于R-CNN的物体检测](https://blog.csdn.net/hjimce/article/details/50187029)       
* [R-CNN论文详解](https://blog.csdn.net/u014696921/article/details/52824097)         
* [深度学习（六十四）Faster R-CNN物体检测](https://blog.csdn.net/hjimce/article/details/73382553)
* [先理解Mask R-CNN的工作原理，然后构建颜色填充器应用](https://zhuanlan.zhihu.com/p/34816076)
* [人脸检测和识别算法综述]()      
    * [人脸检测算法综述 ](https://zhuanlan.zhihu.com/p/36621308)          
    * [人脸检测背景介绍和发展现状](https://zhuanlan.zhihu.com/p/32702868)
    * [人脸识别算法演化史](https://zhuanlan.zhihu.com/p/36416906)
    * [CascadeCNN](https://blog.csdn.net/shuzfan/article/details/50358809)  
    * [MTCNN](https://blog.csdn.net/qq_14845119/article/details/52680940)
* [语义分割卷积神经网络快速入门](https://blog.csdn.net/qq_20084101/article/details/80455877)          
* [图像语义分割的工作原理和CNN架构变迁](https://zhuanlan.zhihu.com/p/38033032)                 
* [CapsNet入门系列](http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247484099&idx=1&sn=97e209f1a9860c8d8c51e81d98fc8a0a&chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&scene=21#wechat_redirect)
  * [CapsNet入门系列之一：胶囊网络背后的直觉](http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247484099&idx=1&sn=97e209f1a9860c8d8c51e81d98fc8a0a&chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&scene=21#wechat_redirect)
  * [CapsNet入门系列之二：胶囊如何工作](http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247484165&idx=1&sn=0ca679e3a5f499f8d8addb405fe3df83&chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&scene=21#wechat_redirect)
  * [CapsNet入门系列之三：囊间动态路由算法](http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247484433&idx=1&sn=3afe4605bc2501eebbc41c6dd1af9572&chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&scene=21#wechat_redirect)
  * [CapsNet入门系列之四：胶囊网络架构](https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw)
* [YOLO](http://www.mamicode.com/info-detail-2314392.html)
* [目标检测|YOLOv2原理与实现(附YOLOv3)](https://zhuanlan.zhihu.com/p/35325884?group_id=966229905398362112)
* [目标检测模型YOLO v3问世](https://zhuanlan.zhihu.com/p/34995629)
* [Attention](http://www.cnblogs.com/shouhuxianjian/p/7903097.html)， [1](https://zhuanlan.zhihu.com/p/31547842)，[2](https://blog.csdn.net/yideqianfenzhiyi/article/details/79422857)，[3](https://blog.csdn.net/Wayne2019/article/details/78488142)，[4](https://zhuanlan.zhihu.com/p/37601161)，[5](https://blog.csdn.net/bvl10101111/article/details/78470716)		
	* 读取器读取原始数据(例如源语句中的源词)并将其转换为分布式表示,其中
一个特征向量与每个词的位置相关联。
	* 存储器存储读取器输出的特征向量列表。这可以被理解为包含事实序列的存储
器,而之后不必以相同的顺序从中检索,也不必访问全部。
	* 最后一个程序利用存储器的内容顺序地执行任务,每个时间步聚焦于某个存储
器元素的内容(或几个,具有不同权重)。
* [一文读懂卷积神经网络中的1x1卷积核](https://zhuanlan.zhihu.com/p/40050371)		
* [目标检测之CornerNet](https://arxiv.org/abs/1808.01244), [1](https://zhuanlan.zhihu.com/p/41825737), [2](https://blog.csdn.net/Hibercraft/article/details/81637451), [3](https://zhuanlan.zhihu.com/p/41759548)
* [人群计数](http://chuansong.me/n/443237851736), [1](https://www.cnblogs.com/wmr95/p/8134692.html), [2](https://blog.csdn.net/u011285477/article/details/51954989), [3](https://blog.csdn.net/qingqingdeaini/article/details/79922549)
* [RelationNetwork](https://www.zhihu.com/question/60784169)
* [ShuffleNet V2和四个网络架构设计准则](https://zhuanlan.zhihu.com/p/40980942)
* [【Tensorflow】tf.nn.depthwise_conv2d如何实现深度卷积?](https://blog.csdn.net/mao_xiao_feng/article/details/78003476)	
* [Tensorflow】tf.nn.atrous_conv2d如何实现空洞卷积？](https://blog.csdn.net/mao_xiao_feng/article/details/78003730)
* [【Tensorflow】tf.nn.separable_conv2d如何实现深度可分卷积?](https://blog.csdn.net/mao_xiao_feng/article/details/78002811)	
* [【TensorFlow】tf.nn.conv2d_transpose是怎样实现反卷积的？](https://blog.csdn.net/mao_xiao_feng/article/details/71713358)

#### Action			
* [先读懂CapsNet架构然后用TensorFlow实现](https://zhuanlan.zhihu.com/p/30753326)
* [TensorFlow Object Detection API 教程](https://blog.csdn.net/qq_36148847/article/details/79306762)
	* [TensorFlow 对象检测 API 教程1](https://blog.csdn.net/qq_36148847/article/details/79306762)
	* [TensorFlow 对象检测 API 教程2](https://blog.csdn.net/qq_36148847/article/details/79307598)
	* [TensorFlow 对象检测 API 教程3](https://blog.csdn.net/qq_36148847/article/details/79307751)
	* [TensorFlow 对象检测 API 教程 4](https://blog.csdn.net/qq_36148847/article/details/79307931)
	* [TensorFlow 对象检测 API 教程5](https://blog.csdn.net/qq_36148847/article/details/79307933)

### GAN     

#### 发展史      

* [千奇百怪的GAN变体](https://zhuanlan.zhihu.com/p/26491601)      
* [The GAN Landscape：Losses, Architectures, Regularization, and Normalization](https://arxiv.org/pdf/1807.04720.pdf)
* [深度学习新星：GAN的基本原理、应用和走向](https://www.leiphone.com/news/201701/Kq6FvnjgbKK8Lh8N.html)

#### 教程     

* [1. GAN原理学习笔记](https://zhuanlan.zhihu.com/p/27295635)
* [2. 极端图像压缩的对抗生成网络](https://zhuanlan.zhihu.com/p/35783437?group_id=969598777652420608)
* [3. 台湾大学李宏毅GAN教程](https://www.youtube.com/watch?v=0CKeqXl5IY0&feature=youtu.be)
    * [Basic](https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Basic%20Idea%20(2017.04.21).pdf)
    * [Improving](https://github.com/Mikoto10032/DeepLearning/blob/master/books/GAN-Improving%20GAN%20(2017.05.05).pdf)
* [4. 2017年GAN 计算机视觉相关paper汇总](https://zhuanlan.zhihu.com/p/29882709)
* [5. 在Keras上实现GAN：构建消除图片模糊的应用](https://zhuanlan.zhihu.com/p/35030377)
* [6. CycleGAN：图片风格，想换就换 | ICCV 2017论文解读](https://zhuanlan.zhihu.com/p/34711316)
* [7. Wasserstein GAN](https://zhuanlan.zhihu.com/p/25071913)      
* [用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）](https://zhuanlan.zhihu.com/p/40105143)
#### Action     

* [1. GAN学习指南：从原理入门到制作生成Demo](https://zhuanlan.zhihu.com/p/24767059)    
* [2. 机器之心GitHub项目：GAN完整理论推导与实现](https://zhuanlan.zhihu.com/p/29837245)     

### RNN      

#### 发展史      

* [从90年代的SRNN开始，纵览循环神经网络27年的研究进展](https://zhuanlan.zhihu.com/p/32668465)       

#### 教程     

* [完全图解RNN、RNN变体、Seq2Seq、Attention机制](https://zhuanlan.zhihu.com/p/28054589)
* [循环神经网络(RNN, Recurrent Neural Networks)介绍](https://blog.csdn.net/heyongluoyao8/article/details/48636251)
* [RNN以及LSTM的介绍和公式梳理](https://blog.csdn.net/Dark_Scope/article/details/47056361)
* [深度学习其五 循环神经网络](https://zybuluo.com/hanbingtao/note/541458)                      
* [用循环神经网络进行文件无损压缩：斯坦福大学提出DeepZip](https://zhuanlan.zhihu.com/p/32582764)         
* [吴恩达序列建模课程]()
    * [Coursera吴恩达《序列模型》课程笔记（1）-- 循环神经网络（RNN）](https://zhuanlan.zhihu.com/p/34309635)
    * [Coursera吴恩达《序列模型》课程笔记（2）-- NLP & Word Embeddings](https://zhuanlan.zhihu.com/p/34975871)
    * [Coursera吴恩达《序列模型》课程笔记（3）-- Sequence models & Attention mechanism](https://zhuanlan.zhihu.com/p/35532553)
* [Word2Vec]()          
    * [word2vec原理(一) CBOW与Skip-Gram模型基础](https://www.cnblogs.com/pinard/p/7160330.html)       
    * [word2vec原理(二) 基于Hierarchical Softmax的模型](http://www.cnblogs.com/pinard/p/7243513.html)        
    * [word2vec原理(三) 基于Negative Sampling的模型 ](http://www.cnblogs.com/pinard/p/7249903.html)        
    * [用gensim学习word2vec ](http://www.cnblogs.com/pinard/p/7278324.html)        

#### Action     

* [tensorflow中RNNcell源码分析以及自定义RNNCell的方法](https://blog.csdn.net/liuchonge/article/details/78405185?locationNum=8&fps=1)     
* [TensorFlow中RNN实现的正确打开方式](https://zhuanlan.zhihu.com/p/28196873)      
* [TensorFlow RNN 代码](https://zhuanlan.zhihu.com/p/27906426)

### LSTM      

#### 教程     

* [1. （译）理解长短期记忆(LSTM) 神经网络](https://zhuanlan.zhihu.com/p/24018768)
* [2. 一文读懂LSTM和RNN](https://zhuanlan.zhihu.com/p/35878575?group_id=970350175025385472)
* [3. 探索LSTM：基本概念到内部结构](https://zhuanlan.zhihu.com/p/27345523)
* [4. 翻译：深入理解LSTM系列](https://blog.csdn.net/matrix_space/article/details/53374040)                      
    * [深入理解 LSTM 网络 (一)](https://blog.csdn.net/matrix_space/article/details/53374040)
    * [深入理解 LSTM 网络 (二)](https://blog.csdn.net/matrix_space/article/details/53376870)
* [LSTM](https://zhuanlan.zhihu.com/p/32085405)

#### Action			

* [用tensorflow LSTM如何预测股票价格](https://zhuanlan.zhihu.com/p/33186759)
* [TensorFlow的多层LSTM实践](https://zhuanlan.zhihu.com/p/29797089)
* [《安娜卡列尼娜》文本生成——利用TensorFlow构建LSTM模型](https://zhuanlan.zhihu.com/p/27087310)

## 深度模型的优化    

* [1. 优化算法纵览](http://fa.bianp.net/teaching/2018/eecs227at/)
* [2. 从梯度下降到Adam](https://zhuanlan.zhihu.com/p/27449596)
* [3. 从梯度下降到拟牛顿法：盘点训练神经网络的五大学习算法](https://zhuanlan.zhihu.com/p/25703402)
* [4. 正则化技术总结](https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800)
  * [1. \[视频讲解\]史上最全面的正则化技术总结与分析--part1](https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800)
  * [2. \[视频讲解\]史上最全面的正则化技术总结与分析--part2](https://zhuanlan.zhihu.com/p/35432128?group_id=966443101011738624)
* [5. 最优化算法系列（math）](https://blog.csdn.net/chunyun0716/article/category/6188191/2)
* [6. 神经网络训练中的梯度消失与梯度爆炸](https://zhuanlan.zhihu.com/p/25631496)        
* [7. 神经网络的优化及训练](https://zhuanlan.zhihu.com/p/36050743)
* [8. 通俗讲解查全率和查准率](https://zhuanlan.zhihu.com/p/35888543)
* [9. 激活函数一览](https://zhuanlan.zhihu.com/p/30567264)
* [10. Coursera吴恩达《优化深度神经网络》课程笔记（3）-- 超参数调试、Batch正则化和编程框架](https://zhuanlan.zhihu.com/p/30922689)
* [11. 机器学习各种熵](https://zhuanlan.zhihu.com/p/35423404)
* [12. 距离和相似性度量](https://zhuanlan.zhihu.com/p/27305237)
* [13. 机器学习里的黑色艺术：normalization, standardization, regularization](https://zhuanlan.zhihu.com/p/29974820)
* [14. LSTM系列的梯度问题](https://zhuanlan.zhihu.com/p/36101196)
* [15. 损失函数整理](https://zhuanlan.zhihu.com/p/35027284)
* [16. 详解残差块为何有助于解决梯度弥散问题](https://zhuanlan.zhihu.com/p/28124810)
* [17. FAIR何恺明等人提出组归一化：替代批归一化，不受批量大小限制](https://zhuanlan.zhihu.com/p/34858971)
* [18. Batch Normalization（BN）]():[1 ](https://zhuanlan.zhihu.com/p/26702482),[2 ](https://blog.csdn.net/hjimce/article/details/50866313),[3 ](https://blog.csdn.net/malefactor/article/details/51476961),[4 ](https://blog.csdn.net/edogawachia/article/details/80040456), [5](https://zhuanlan.zhihu.com/p/38176412)
* [19. 详解深度学习中的Normalization，不只是BN](https://zhuanlan.zhihu.com/p/33173246)
* [20. BFGS](https://blog.csdn.net/philosophyatmath/article/details/70173128)
* [21. 详解深度学习中的梯度消失、爆炸原因及其解决方法](https://zhuanlan.zhihu.com/p/33006526)
* [22. Dropout](https://arxiv.org/pdf/1207.0580.pdf), [1](https://blog.csdn.net/stdcoutzyx/article/details/49022443), [2](https://blog.csdn.net/hjimce/article/details/50413257), [3](https://blog.csdn.net/shuzfan/article/details/50580915)

## 炼丹术士那些事
* [训练的神经网络不工作？一文带你跨过这37个坑](https://blog.csdn.net/jiandanjinxin/article/details/77190687)
* [深度学习与计算机视觉系列(8)_神经网络训练与注意点](https://blog.csdn.net/han_xiaoyang/article/details/50521064)
* [神经网络训练loss不下降原因集合](https://blog.csdn.net/liuweiyuxiang/article/details/80856991)
* [机器学习：如何找到最优学习率](https://blog.csdn.net/whut_ldz/article/details/78882871)及[实现](https://github.com/L1aoXingyu/torchlib)
* [不平衡数据集处理方法](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)
* [同一个神经网络使用不同激活函数的表达能力是否一致](https://www.zhihu.com/question/41841299)
* [梯度下降优化算法回顾](http://ruder.io/optimizing-gradient-descent/)
* [论文笔记之数据增广：mixup](https://blog.csdn.net/ly244855983/article/details/78938667#%E8%AE%A8%E8%AE%BA)
* [避坑指南：数据科学家新手常犯的13个错误](https://zhuanlan.zhihu.com/p/44331706)	
* [凭什么相信CNN的结果?--可视化](https://bindog.github.io/blog/2018/02/10/model-explanation/)				
	* [凭什么相信你，我的CNN模型？（篇一：CAM和Grad-CAM)](https://bindog.github.io/blog/2018/02/10/model-explanation/)
	* [凭什么相信你，我的CNN模型？（篇二：万金油LIME)](http://bindog.github.io/blog/2018/02/11/model-explanation-2/)
	* [论文笔记:Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://www.jianshu.com/p/294ad9ae2e50)
	* [CV：基于Keras利用训练好的hdf5模型进行目标检测实现输出模型中的表情或性别的gradcam(可视化)](https://blog.csdn.net/qq_41185868/article/details/80323646)
* [大卷积核还是小卷积核?]() [1](https://www.jianshu.com/p/d75375dd7ebd), [2](https://blog.csdn.net/kuangtun9713/article/details/79475457)	
	
## 机器学习、深度学习基础理论    

### 信息论				

* [1. 机器学习中的各种熵](https://zhuanlan.zhihu.com/p/35423404)    
* [2. 从香农熵到手推KL散度：纵览机器学习中的信息论](https://zhuanlan.zhihu.com/p/32985487)

## 深度学习相关算法    

### SVD			

* [1. 关于奇异值分解SVD的总结（PCA、LDI）](https://zhuanlan.zhihu.com/p/30482640)
* [2. 奇异值分解（SVD）](https://zhuanlan.zhihu.com/p/29846048)
* [3. 奇异值分解(SVD)原理详解及推导](https://blog.csdn.net/zhongkejingwang/article/details/43053513)    
* [4. SVD在推荐系统中的应用详解以及算法推导](https://blog.csdn.net/zhongkejingwang/article/details/43083603)

### 迁移学习			

* [1. 迁移学习：经典算法解析](https://blog.csdn.net/linolzhang/article/details/73358219)
* [2. 什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？](https://www.zhihu.com/question/41979241)
* [3. 迁移学习个人笔记](https://github.com/Mikoto10032/DeepLearning/blob/master/notes/日常阅读笔记/2018_4_12_迁移学习.pdf)  
* [迁移学习总结(One Shot Learning, Zero Shot Learning)](https://blog.csdn.net/XJTU_NOC_Wei/article/details/77850221)

### 域自适应

* [Domain Adaptation视频教程（附PPT）及经典论文分享](https://zhuanlan.zhihu.com/p/27519182)
* [模型汇总15 领域适应性Domain Adaptation、One-shot/zero-shot Learning概述](https://zhuanlan.zhihu.com/p/27449079)
* [【深度学习】论文导读：无监督域适应（Deep Transfer Network: Unsupervised Domain Adaptation）](https://blog.csdn.net/mao_xiao_feng/article/details/54426101)
* [【论文阅读笔记】基于反向传播的无监督域自适应研究
](https://zhuanlan.zhihu.com/p/37298073)
* [【Valse大会首发】领域自适应及其在人脸识别中的应用](https://zhuanlan.zhihu.com/p/21441807)
* [CVPR 2018：基于域适应弱监督学习的目标检测](https://zhuanlan.zhihu.com/p/41126114)

### 元学习		

* [OpenAI提出新型元学习方法EPG，调整损失函数实现新任务上的快速训练](https://zhuanlan.zhihu.com/p/35869158?group_id=970310501209645056)      

### 强化学习			

* [强化学习（Reinforcement Learning）知识整理](https://zhuanlan.zhihu.com/p/25498081)
* [强化学习从入门到放弃的资料](https://zhuanlan.zhihu.com/p/34918639)
* [强化学习入门](https://zhuanlan.zhihu.com/p/25498081)
    * [强化学习入门 第一讲 MDP](https://zhuanlan.zhihu.com/p/25498081)
* [强化学习——从Q-Learning到DQN到底发生了什么？](https://zhuanlan.zhihu.com/p/35882937)
* [从强化学习到深度强化学习（上）](https://zhuanlan.zhihu.com/p/35688924)                  
* [从强化学习到深度强化学习（下）](https://zhuanlan.zhihu.com/p/35965070)
* [一文带你理解Q-Learning的搜索策略](https://zhuanlan.zhihu.com/p/37048004)

### 马尔科夫决策			

* [马尔科夫决策过程之Markov Processes（马尔科夫过程）](https://zhuanlan.zhihu.com/p/35124726)
* [马尔科夫决策过程之Markov Reward Process（马尔科夫奖励过程）](https://zhuanlan.zhihu.com/p/35231424)
* [马尔科夫决策过程之Bellman Equation（贝尔曼方程）](https://zhuanlan.zhihu.com/p/35261164)
* [马尔科夫决策过程之Markov Decision Process(马尔科夫决策过程)](https://zhuanlan.zhihu.com/p/35354956)
* [马尔科夫决策过程之最优价值函数与最优策略](https://zhuanlan.zhihu.com/p/35373905)

### 推荐算法      	

* [推荐算法相关的文档整理](https://zhuanlan.zhihu.com/p/29969721)              

### 自然语言处理（NLP）		

* [基于word2vec训练词向量(一)](https://zhuanlan.zhihu.com/p/35648927)
* [基于word2vec训练词向量(二)](https://zhuanlan.zhihu.com/p/35889385)
* [自然语言处理中的自注意力机制（Self-Attention Mechanism）](https://zhuanlan.zhihu.com/p/35041012)      
* [YJango的Word Embedding--介绍](https://zhuanlan.zhihu.com/p/27830489)          
* [CMU&谷歌大脑提出新型问答模型QANet](https://zhuanlan.zhihu.com/p/37168143)          

### 语义分割相关算法    		
      
* [干货 | 一文概览主要语义分割网络](https://blog.csdn.net/qq_20084101/article/details/80432960)
* [深度学习中IU、IoU(Intersection over Union)](https://blog.csdn.net/iamoldpan/article/details/78799857)
* [Selective Search for Object Detection ](https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/)[（译文）](https://blog.csdn.net/guoyunfei20/article/details/78723646)
* [NMS——非极大值抑制](https://blog.csdn.net/shuzfan/article/details/52711706)
* [边框回归(Bounding Box Regression)详解](https://blog.csdn.net/zijin0802034/article/details/77685438)

## 机器学习相关算法    

* [ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结](https://zhuanlan.zhihu.com/p/34534004)
* [数据挖掘十大算法简要说明](http://www.cnblogs.com/en-heng/p/5013995.html)
* [AdaBoost到GBDT系列]()
  * [当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting](https://zhuanlan.zhihu.com/p/25096501?refer=data-miner)
  * [当我们在谈论GBDT：Gradient Boosting 用于分类与回归](https://zhuanlan.zhihu.com/p/25257856?refer=data-miner)
  * [当我们在谈论GBDT：其他 Ensemble Learning 算法](https://zhuanlan.zhihu.com/p/25443980)
* [集成学习之bagging,stacking,boosting概念理解](https://zhuanlan.zhihu.com/p/41809927)

### 决策树(Decision Tree)   
* [Python3《机器学习实战》学习笔记（二）：决策树基础篇之让我们从相亲说起](https://blog.csdn.net/c406495762/article/details/75663451)
* [Python3《机器学习实战》学习笔记（三）：决策树实战篇之为自己配个隐形眼镜](https://blog.csdn.net/c406495762/article/details/76262487)
* [机器学习实战教程（十三）：树回归基础篇之CART算法与树剪枝](http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html)
* [《机器学习实战》基于信息论的三种决策树算法(ID3,C4.5,CART)](https://blog.csdn.net/gamer_gyt/article/details/51242815)
* [说说决策树剪枝算法](https://zhuanlan.zhihu.com/p/31404571)
* [机器学习实战 第九章 树回归](https://blog.csdn.net/namelessml/article/details/52595066)
* [决策树值ID3、C4.5实现](https://blog.csdn.net/u014688145/article/details/53212112)
* [决策树值CART实现](https://blog.csdn.net/u014688145/article/details/53326910)

### 支持向量机(SVM)    

* [SVM通俗导论 July（本文章是我看过最好的SVM导论）](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%80%9A%E4%BF%97%E5%AF%BC%E8%AE%BA%EF%BC%88%E7%90%86%E8%A7%A3SVM%E7%9A%84%E4%B8%89%E5%B1%82%E5%A2%83%E7%95%8C%EF%BC%89LaTeX%E6%9C%80%E6%96%B0%E7%89%88_2015.1.9.pdf)      
* [Python3《机器学习实战》学习笔记（八）：支持向量机原理篇之手撕线性SVM （SMO训练过程总结得清晰易懂）](https://blog.csdn.net/c406495762/article/details/78072313)      
* [svm核函数的理解和选择](https://blog.csdn.net/leonis_v/article/details/50688766)
* [核函数和径向基核函数 (Radial Basis Function)--RBF](https://blog.csdn.net/huang1024rui/article/details/51510611)                        
* [SVM核函数](https://blog.csdn.net/xiaowei_cqu/article/details/35993729)        

### LDA
* [教科书上的LDA为什么长这个样子？](https://zhuanlan.zhihu.com/p/42238953)

### 标签传播算法(Label Propagation Algorithm)    

* [标签传播算法（Label Propagation）及Python实现](https://blog.csdn.net/zouxy09/article/details/49105265)
    * [参考资料](https://github.com/Mikoto10032/DeepLearning/blob/master/books/Semi-Supervised%20Learning%20with%20Graphs.pdf)

### 蒙塔卡罗搜索树			

* [蒙特卡洛树搜索入门指南](https://zhuanlan.zhihu.com/p/34950988)

### GBDT		

* [LightGBM大战XGBoost](https://zhuanlan.zhihu.com/p/35645973)
* [概述XGBoost、Light GBM和CatBoost的同与不同](https://zhuanlan.zhihu.com/p/34698733)    
* [梯度提升决策树](https://zhuanlan.zhihu.com/p/36339161)
* [GBDT原理及应用](https://zhuanlan.zhihu.com/p/30339807)
* [XGBOOST原理篇](https://zhuanlan.zhihu.com/p/31654000)

### 集成(EM)			

* [集成学习法之bagging方法和boosting方法](https://blog.csdn.net/qq_30189255/article/details/51532442)
* [Bagging,Boosting,Stacking](https://blog.csdn.net/Mr_tyting/article/details/72957853)
* [人人都懂的EM算法 ](https://zhuanlan.zhihu.com/p/36331115)                      

### 条件随机场(CRF, 判别式模型)
* [如何轻松愉快地理解条件随机场（CRF）？](https://www.jianshu.com/p/55755fc649b1)
* [如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？](https://www.zhihu.com/question/35866596)
* [HMM ,MHMM,CRF 优缺点与区别](https://blog.csdn.net/u013378306/article/details/55213029)

### TSNE
* [流形学习-高维数据的降维与可视化](https://blog.csdn.net/u012162613/article/details/45920827)
* [tSNE](https://blog.csdn.net/flyingzhan/article/details/79521765)

## 工具平台使用  

### Tensorflow		

* [【干货】史上最全的Tensorflow学习资源汇总](https://zhuanlan.zhihu.com/p/35515805?group_id=967136289941897216)
* [《21个项目玩转深度学习———基于TensorFlow的实践详解》](https://github.com/hzy46/Deep-Learning-21-Examples)  

### MXNet		

* [Gluon](https://github.com/Mikoto10032/DeepLearning/blob/master/books/gluon_tutorials_zh（基于MXNet）.pdf)

### Python3.x			

* [廖雪峰Python教程](https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000)
* [菜鸟教程](http://www.runoob.com/python3/python3-tutorial.html)                        

### 标注工具
* BoundingBox
	* [labelImg](https://github.com/tzutalin/labelImg)
* Segmentation
	* [labelme](https://github.com/wkentaro/labelme)

## 数据集  		

* [1. 25个深度学习相关公开数据集](https://zhuanlan.zhihu.com/p/35449783)
* [2. 自然语言处理（NLP）数据集](https://zhuanlan.zhihu.com/p/35423943)
* [3.全唐诗(43030首)](https://pan.baidu.com/s/1o7QlUhO)
* [4. 伯克利大学公开数据集](https://people.eecs.berkeley.edu/~taesung_park/)
* [5. ACL 2018资源：100+ 预训练的中文词向量](https://zhuanlan.zhihu.com/p/36835964)
* [6. 预训练中文词向量](https://github.com/Embedding/Chinese-Word-Vectors)
* [7. 公开数据集种子库](http://academictorrents.com)
* [8. 数据集】计算机视觉，深度学习，数据挖掘数据集整理](https://blog.csdn.net/c20081052/article/details/79814082)
* [9. 计算机视觉著名数据集CV Datasets](https://blog.csdn.net/accepthjp/article/details/51831026)
* [10. 计算机视觉相关数据集和比赛](https://blog.csdn.net/NNNNNNNNNNNNY/article/details/68485160)
* [11. 这是一份非常全面的开源数据集，你，真的不想要吗？](https://zhuanlan.zhihu.com/p/43846002)
* [12. 人群密度估计现有主要数据集特点及其比较](https://blog.csdn.net/weixin_40516558/article/details/81564464)
* [13. DANBOORU2017: A LARGE-SCALE CROWDSOURCED AND TAGGED ANIME ILLUSTRATION DATASET](https://www.gwern.net/Danbooru2017)

## To do list:		
* [Inter Covariate shift](https://blog.csdn.net/mao_xiao_feng/article/details/54317852)     
*  - [x] [Transposed Convolution, Fractionally Strided Convolution or Deconvolution](https://buptldy.github.io/2016/10/29/2016-10-29-deconv/)
* - [ ] 2014机器学习个人笔记、cs231、2011机器学习个人笔记、深度学习
* 将收藏过的文章转移到此项目（一直持续）     
* **准备新建个论文索引项目，将看过的论文保存（按照方向、年份、名称排序）**            
* **重新调整本项目的结构（该方向的综述或者迅速纵览，详细解释文章，实战（包括测试和训练））**
* **将看过的论文的模型的test代码和train代码跑通**
	*	准备跑通YOLO系列模型
		*	- [x] YOLOv1 tensorflow版本test代码跑通
		*	- [x] YOLOv1 tensorlfow版本train代码跑通
		*	- [x] YOLOv3 darknet版本test跑通
		*	- [x] YOLOv3 darknet版本train跑通 
